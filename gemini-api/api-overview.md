# Gemini API Overview

## Models

- To get more detailed model information refer to the Gemini page.

- You can also use the `list_models` method to list all the models available and then the `get_model` method to get the metadata for a particular model.

## Prompt data and design

- For information on the token limits for specific models, see Gemini.

- Prompts using the Gemini AP cannot exceed 20MB in size.

- The Gemini API provides a File API for temporarily storing media files for using in prompting, which lets you provide prompt data beyond the 20MB limit.

    - See API Reference > files > Overview.

- For more information on using the File API and file formats supported prompting, see Prompting > Prompting with media files.

### Prompt design design and text input

- See Prompting > Intro to prompt design for guidance on how to approach prompting and About generative models > Prompt 101 guide to learn about different approaches to prompting.

## Generate content

- The Gemini API lets you use bot text and image data for prompting, depending on what model variation you use.

- For example, you can generate text using text prompts with the `gemini-pro` model and use both text and image data to prompt the `gemini-pro-vision` model.

- This section gives simple code examples of each.

- Refer to the API reference > models > generateContent for a more detailed example that covers all of the parameters.

### Text only input

- This features lets you perform natural language processing (NLP) tasks such as text completion and summarization.

- See the Getting started tutorials > Tutorial > Python.

```python
model = genai.GenerativeModel('gemini-pro')
prompt = "Write a story about a magic backpack."
response = model.generate_content(prompt)
```

### Multi-turn conversations (chat)

- You can use the Gemini API to build interactive chat experiences for your users.

- Using the chat feature of the AP lets you collect multiple rounds of questions and responses, allowing users to incrementally step toward answers or get help with multi-part problems.

```python
model = genai.GenerativeModel('gemini-pro'))
chat = model.start_chat(history = [])

response = chat.send_message(
        "Pretend you\'re a snowman and stay in character for each response.")
print(response.text)

response = chat.send_message("What\' your favorite season of the year?")
print(response.text)
```

- See the Getting started tutorials > Tutorial > Python.

### Streamed responses

- The Gemini API provides an additional way to receive responses from generative AI models: as a data stream.

- A streamed response sends incremental pieces of data back to your application as it is generated by the model.

```python
prompt = "Write a story about a magic backpack."

response = genai.stream_generate_content(model = "models/genimi1pro",
                                         prompt = prompt)
```

- See the Getting started tutorials > Tutorial > Python.

### JSON format responses

- The Gemini API provides a configuration parameter to request a response in JSON format.

> ##### Note
>
> - This response configuration option is supported only with the Gemini 1.5 Pro model.

- You use this output feature by setting the `response_mime_type` configuration option to `application/json` and including a JSON format specification in the body of your request.

```sh
$ curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=$API_KEY \
    -H 'Content-Type: application/json' \
    -X POST \
    -d '{ "contents":[{
            "parts":[{"text": "List 5 popular cookie recipes using this JSON schema: \{ \"type\": \"object\", \"properties\": \{ \"recipe_name\": \{ \"type\": \"string\" \},\}\}"}] }],
          "generationConfig": {"response_mime_type": "application/json",} }'
```

## Embeddings

- The embedding service in the Gemini AP generates stat-of-the-art embeddings for words, phrases, and sentences.

- The resulting embeddings can then be used for NLP tasks, such as semantic search, text classification, and clustering, among many others.

- See Embeddings to learn what embeddings are and some key use cases for the embedding service to help you get started.

## Next steps

- Get started with the Google AI Studio UI using the Google AI Studio quickstart.

- Try out server-side access to the Gemini API with the Get started tutorials > Tutorial.
